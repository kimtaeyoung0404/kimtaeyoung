# crawling-data
데이터 크롤링
####  참고 링크 
```
https://keep-steady.tistory.com/29
```
#### 노트북에서 좌측 하단에 cmd 창을 열고 시작

``` bash
C:\Users\user>cd ..

C:\Users>cd ..

C:\>mkdir project_ai
cd mkdir project_ai
```
```
git clone --depth 1 https://github.com/YoongiKim/AutoCrawler
```
<b>
  결과
remote: Counting objects: 100% (12/12), done.
remote: Compressing objects: 100% (11/11), done.
remote: Total 12 (delta 0), reused 8 (delta 0), pack-reused 0
Receiving objects: 100% (12/12), 16.48 MiB | 2.30 MiB/s, done.

``` bash
cd AutoCrawler
C:\project_ai\AutoCrawler>pip install -r requirements.txt
```
<b>
장원영
카리나
윈터
수지

를 내 컴퓨터 -> 로컬 디스크 C->projetcs-> AutoCroawler-> kewwords.txt 에 dog, cat 지우고 넣어준 후 저장
크롤링 실행
